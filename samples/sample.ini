# This is the overall configuration file for the MPI test suite.  It
# downloads an MPI implementation, potentially builds it, and installs
# it.  If the MPI is installed successfully, the framework then builds
# some tests against the installed MPI.  If they are compiled
# successfully, the tests are then run.

# Results are recorded in a variety of different ways (e.g., sent back
# to a central database, e-mailed to a specified e-mail address,
# dumped to a file, etc.). 

#======================================================================
# Overall configuration
#======================================================================

[MTT]
save_successful = 0
save_failed_gets = 1
save_failed_installs = 3
save_failed_builds = 1
save_failed_runs = 1

#======================================================================
# MPI get phase
#======================================================================

# The following keys are permitted in the MPI get sections:

# module: name of the module that will do this download (must be
#     specified)

# Other keys may be allowed, but will be specified by the module that
# is performing the download (however, most use the key "url" as an
# indicator as to where to download from).

#----------------------------------------------------------------------

[>>>SKIP<<< MPI get: ompi-binary-tarball]
pretty_name = Open MPI Binary Tarball
mpi_name = Open MPI
mpi_installer = Open MPI copy binary tree

module = Tarball
tarball = /u/jsquyres/svn/mtt/ompi-bin-install.tar.gz

#----------------------------------------------------------------------

[MPI get: ompi-nightly-trunk]
pretty_name = Open MPI nightly snapshot / trunk
mpi_name = Open MPI
mpi_installer = Open MPI build

module = OMPI_Snapshot
url = http://www.open-mpi.org/nightly/trunk

#----------------------------------------------------------------------

[>>>SKIP<<< MPI get: jsquyres copytree]
pretty_name = Open MPI nightly export from a long time ago
mpi_name = Open MPI
mpi_installer = Open MPI build

module = Copytree
directory = /u/jsquyres/svn/ompi-trunk-export
version = &shell("./config/ompi_get_version.sh VERSION --full")
post_copy = <<EOT
./autogen.sh
EOT

#----------------------------------------------------------------------

[>>>SKIP<<< MPI get: ompi svn trunk]
pretty_name = Open MPI SVN trunk checkout
mpi_name = Open MPI
mpi_installer = Open MPI build

module = SVN
url = https://svn.open-mpi.org/svn/ompi/trunk
post_export = <<EOT
pwd
ls -l
./autogen.sh
EOT

#----------------------------------------------------------------------

[>>>SKIP<<< MPI get: ompi tarball]
pretty_name = Open MPI old tarball (r7998)
mpi_name = Open MPI
mpi_installer = Open MPI build

module = Tarball
tarball = /u/jsquyres/tarball/openmpi-1.1a1r7998.tar.bz2

#======================================================================
# Install MPI phase
#======================================================================

# The following keys are permitted in the sub-BuildMPI sections:

# perfbase_xml: Perfbase XML file to use on the server side the
#        analyze and parse the output (default: inp_mpi_install.xml)
# module: module name (must be specified)
# compiler_name: one of: gnu pgi intel kai absoft pathscale (must be specified)
# compiler_version: usually a &shell() expression to get the compiler's version
# vpath_mode: none, absolute, relative (default "none")
# make_all_arguments: given to "make $arguments all" (default "")
# configure_arguments: given to "configure $arguments" (default "")
# separate_stdout_stderr: logical, whether to separate out stderr and
#                         stdout or not (default: 0)
# make_check: logical, whether to run "make check" or not (default: 1)

# These keys are also accepted in sub-BuildMPI sections, but are
# listed separately because they are also accepted elsewhere.  They
# are called the Environment Keys.

# setenv: name value
# unsetenv: name
# prepend_path: name value
# append_path: name value

# Other keys may be allowed, but will be specified by the module that
# is performing the build.

#----------------------------------------------------------------------

[>>>SKIP<<< MPI install: odin gcc default]
pretty_name = Gcc default build
mpi_name = Open MPI
mpi_installer = Open MPI build
perfbase_xml = inp_mpi_install.xml

module = OMPI
setenv = BuildMPI_FOO this is a test
vpath_mode = none
make_all_arguments = -j 4
make_check = 1
compiler_name = gnu
separate_stdout_stderr = 0
compiler_version = &shell("gcc --version | head -n 1 | awk '{ print \$3 }'")
configure_arguments = CFLAGS=-g --enable-debug --disable-mpi-f90

#----------------------------------------------------------------------

[MPI install: odin gcc warnings]
pretty_name = Gcc warnings build
mpi_name = Open MPI
mpi_installer = Open MPI build
perfbase_xml = inp_mpi_install.xml

module = OMPI
vpath_mode = none
make_all_arguments = -j 4
make_check = 1
compiler_name = gnu
separate_stdout_stderr = 1
compiler_version = &shell("gcc --version | head -n 1 | awk '{ print \$3 }'")
configure_arguments = CFLAGS=-g --enable-picky --enable-debug --disable-mpi-f90
setenv = my_variable_name bogus value

#----------------------------------------------------------------------

[MPI install: copy bin tree]
pretty_name = Gcc warnings build
mpi_name = Open MPI
mpi_installer = Open MPI copy binary tree
perfbase_xml = inp_mpi_install.xml
compiler_name = none
compile_version = none

module = Copytree

#======================================================================
# MPI run details
#======================================================================

[MPI Details: ompi]
pretty_name = Open MPI
mpi_name = Open MPI

exec = mpirun -np &test_np() --prefix &test_prefix() &test_executable() &test_argv()

#----------------------------------------------------------------------

[MPI Details: a good example]
pretty_name = Example only
mpi_name = An example

before_any_exec = <<EOT
echo OMPI: before any exec
EOT

before_each_exec = <<EOT
echo OMPI: before each exec
EOT

exec = mpirun -np &test_np() --prefix &test_prefix() @params@ &test_executable() &test_argv()

after_each_exec = <<EOT
echo OMPI: after each exec
EOT

after_all_exec = <<EOT
echo OMPI: after all exec
EOT

params = &enumerate("--mca pls_slurm_priority 0 --mca pls_rsh_priority 100", \
  "--mca pls_slurm_priority 100 --mca pls_rsh_priorty 0") --mca btl @btls@,self
btls = &enumerate("tcp", "mvapi")


#======================================================================
# Test build phase
#======================================================================

# The following keys are permitted in the sub-BuildTests sections:

# module: module name (no default; must be specified)
# perfbase_xml: Perfbase XML file to use on the server side the
#        analyze and parse the output (default: inp_test_build.xml)

# Test source keys (exactly one of these must be specified).  This
# source will be used for *each* set of tests that are compiled (e.g.,
# if the MPI was built several different ways and "tarball" was
# specified, the tarball will be extracted once for each MPI
# installation):

# copydir: copy the entire tree to a new location for testing
# tarball: expand the tarball for testing
# svn: specify a URL for SVN checkout for testing

# The Environment Keys are also accepted here.  Note that PATH and
# LD_LIBRARY_PATH are automatically prepended with the relevant
# directories for each MPI installation each time a test section is
# built.  Hence, it is not necessary to manually prepend_path for PATH
# or LD_LIBRARY_PATH; it is automatically done for you.

# Also note that all the Environment keys from the relevant [BuildMPI]
# section will be automatically processed before the sub-module is
# invoked to build the tests.  Hence, if an MPI was built with "setenv
# = foo bar", then the environment variable "foo" will be set to the
# value "bar" before the BuildTests section is invoked to build tests
# with that MPI installation.

# Other keys may be allowed, but will be specified by the module that
# is performing the build.

#----------------------------------------------------------------------

[>>>SKIP<<< Test build: intel]
pretty_name = Open MPI / Intel test suite
perfbase_xml = inp_test_build.xml
#source_copydir = /u/jsquyres/svn/ompi-tests/intel_tests
source_tarball = /u/jsquyres/svn/ompi-tests/intel_tests.tar.gz
setenv = TestMPI_BAR2 this is a test

module = Intel_OMPI_Tests
buildfile = coll

#----------------------------------------------------------------------

[>>>SKIP<<< Test build: ibm]
pretty_name = Open MPI / IBM test suite
perfbase_xml = inp_test_build.xml
source_svn = https://svn.open-mpi.org/svn/ompi-tests/trunk/ibm

module = Shell
build_command = <<EOT
./autogen.sh
./configure
make
EOT

#----------------------------------------------------------------------

[>>>SKIP<<< Test build: imb]
pretty_name = Open MPI / IMB test suite
perfbase_xml = inp_test_build.xml
source_tarball = /u/jsquyres/svn/ompi-tests/imb.tar.gz
module = Shell
build_command = <<EOT
cd src
make IMB-MPI1
EOT

#----------------------------------------------------------------------

[Test build: npb]
pretty_name = Open MPI / NPB test suite
perfbase_xml = inp_test_build.xml
source_tarball = /u/jsquyres/svn/ompi-tests/npb.tar.gz

module = NPB_OMPI_Tests

# This has not been implemented yet:
#tests = &enumerate("ep", "cg", "bt", "sp", "is").&enumerate("S", "W", "A", "B", "C").&squares(1, 6)
#tests = &enumerate("ep.W.2", "ep.A.2", "sp.W.2")

npbs = &enumerate("squares", "powers")

# NOTE: BT and SP cannot be run on more than 16 processors

benchmarks_squares = &enumerate("ep", "bt", "sp", "is")
classes_squares = &enumerate("S", "W", "A", "B", "C")
nprocs_squares = &squares(1, 6)
skip_squares = &enumerate("ep.W.36", "bt.C.25")

benchmarks_powers = &enumerate("mg", ft", "lv", "cg")
classes_powers = &enumerate("S", "W", "A", "B", "C")
nprocs_powers = &pow(2, 1, 6)
skip_powers = &enumerate("ep.W.36", "bt.C.25")

#======================================================================
# Test Run phase
#======================================================================

# The following keys are permitted in the test run sections:

# perfbase_xml: Perfbase XML file to use on the server side the
#        analyze and parse the output (default: inp_test_run.xml)
# test_build: indicating which test build will be tested
# argv: arguments to pass to the test after the command name (default:
#        "", i.e., nothing)
# np: number of processes to run (default: 2)
# np_ok: boolean expression to check whether a given number of
#        processes is ok for a specific test.  Is ok to hard-wire to 1
#        if all values of np are acceptable. (default: 1)
# pass: how to check if a test passed (typically an expression)
#        (default: &eq(&test_exit_status(), 0)
# timeout: number of seconds before declaring that a test has failed
#        (i.e., if test runs longer than this, kill the test and rule 
#        that it failed) (default: 30)
# save_output_on_pass: boolean indicating whether you want to save the
#        stdout/stderr even if the test passes (default: 0)
# separate_stdout_stderr: logical, whether to separate out stderr and
#        stdout or not (default: 0)

# module: module name (no default; must be specified)

# Other keys may be allowed, but will be specified by the module that
# is performing the build.

#----------------------------------------------------------------------

[Test run: intel coll]
pretty_name = Collectives
test_build = intel
perfbase_xml = inp_test_run.xml
pass = &eq(&test_exit_status(), 0)
timeout = &max(30, &multiply(10, &test_np()))
save_stdout_on_pass = 0
separate_stdout_stderr = 0

module = Simple
tests = src/&cat("coll")
np = &if(&gt(&slurm_max_procs(), 0), &step(2, &max(2, &slurm_max_procs()), 2), 2)
np_ok = &if(&le(&test_np(), 64), 1, 0)
only_if_exec_exists = 1

#----------------------------------------------------------------------

[Test run: imb]
pretty_name = IMB
test_build = imb
perfbase_xml = inp_test_run.xml
pass = &eq(&test_exit_status(), 0)
timeout = &max(30, &multiply(10, &test_np()))
save_stdout_on_pass = 0
separate_stdout_stderr = 0

#----------------------------------------------------------------------

[>>>SKIP<<< Test run: npb]
pretty_name = NPB v2.3
test_build = npb
perfbase_xml = inp_test_run.xml
pass = &eq(&test_exit_status(), 0)
timeout = &max(30, &multiply(10, &test_np()))
save_stdout_on_pass = 0
separate_stdout_stderr = 0

module = NPB
tests = &tests_built()
# JMS: &tests_built() not yet implemented

#======================================================================
# Reporter phase
#======================================================================

# The following keys are permitted in the reporter sections:

# module: module name (no default; must be specified)

# Other keys are allowed, but will be specified by the reporter module

#----------------------------------------------------------------------

[Reporter: IU database]
module = Perfbase

# The following keys are permitted by the Perfbase module:

# realm: http realm for the response
# username: username
# password: password
# platform: string name identifying this resource
# url: url to post the results to

# Fill these in with relevant values.

#realm = Your realm
#username = your_username
#password = your_password
#platform = Your platform ID string
#url = http://www.example.com/mtt-perfbase-submit/

#----------------------------------------------------------------------

[Reporter: write to text file]
module = TextFile

# The following keys are permitted by the TextFile module:

# file: filename to write to (absolute is better), a single dash ("-")
#     means standard output.  Values that can be in the filename that will
#     be substituted:
#     - $date: mmddyyyy
#     - $time: hhmmss
#     - $mpi_name: ID of the MPI
#     - $mpi_version: version of the MPI
#     - $phase: the phase being reported on
#     - $section: the section of this INI file being reported on
#     The final filename is evaluated as a perl expression, so perl
#     escaping is allowed.
# separator: string, will be placed between subsequent entries in the file

file = test-$phase-$section-$mpi_name-$mpi_version.txt
#separator = >>>>----------------------------------------------------------<<<<

#----------------------------------------------------------------------

[Reporter: write to ini file]
module = INIFile

# The following keys are permitted by the INIFile module:

# file: filename to write to (absolute is better). Values that can be
#     in the filename that will be substituted:
#     - $date: mmddyyyy
#     - $time: hhmmss
#     - $mpi_name: ID of the MPI
#     - $mpi_version: version of the MPI
#     - $phase: the phase being reported on
#     - $section: the section of this INI file being reported on
#     The final filename is evaluated as a perl expression, so perl
#     escaping is allowed.

file = test-$phase-$section-$mpi_name-$mpi_version.ini

#----------------------------------------------------------------------

[Reporter: send email]
module = Email

# The following keys are permitted by the File module:

# to: address to send to
# subject: subject line.  Values that can be in the subject that will
#     be substituted:
#     - $date: mmddyyyy
#     - $time: hhmmss
#     - $mpi_name: ID of the MPI
#     - $mpi_version: version of the MPI
#     - $phase: the phase being reported on
#     - $section: the section of this INI file being reported on
#     The final filename is evaluated as a perl expression, so perl
#     escaping is allowed.

# Fill these in with relevant values.

#to = your_address@example.com
#subject = MPI test results: $phase / $section
